0 Dropout applied to an activation matrix at training time, with rescaling happening during training. At test time the activation matrix is unchanged.
151Improving generalizationI figured it must be because it would require cooperation between employees to suc-cessfully defraud the bank. This made me realize that randomly removing a differentsubset of neurons on each example would prevent conspiracies and thus reduce over-fitting.” The core idea is that introducing noise in the output values of a layer canbreak up happenstance patterns that aren’t significant (what Hinton refers to as con-spiracies), which the model will start memorizing if no noise is present. In Keras, you can introduce dropout in a model via the Dropout layer, which isapplied to the output of the layer right before it. Let’s add two Dropout layers in theIMDB model to see how well they do at reducing overfitting.model = keras.Sequential([    layers.Dense(16, activation="relu"),    layers.Dropout(0.5),    layers.Dense(16, activation="relu"),    layers.Dropout(0.5),    layers.Dense(1, activation="sigmoid")])model.compile(optimizer="rmsprop",              loss="binary_crossentropy",              metrics=["accuracy"])history_dropout = model.fit(    train_data, train_labels,    epochs=20, batch_size=512, validation_split=0.4)Figure 5.21 shows a plot of the results