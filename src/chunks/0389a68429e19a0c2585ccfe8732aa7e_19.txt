edict. Sometimes, annotations can be retrievedautomatically, such as those for the music recommendation task or the click-through-rate prediction task. But often you have to annotate your data by hand. This is a labor-heavy process.INVESTING IN DATA ANNOTATION INFRASTRUCTUREYour data annotation process will determine the quality of your targets, which in turndetermine the quality of your model. Carefully consider the options you have available:Should you annotate the data yourself?Should you use a crowdsourcing platform like Mechanical Turk to collect labels?Should you use the services of a specialized data-labeling company?Outsourcing can potentially save you time and money, but it takes away control. Usingsomething like Mechanical Turk is likely to be inexpensive and to scale well, but yourannotations may end up being quite noisy.
158CHAPTER 6The universal workflow of machine learning To pick the best option, consider the constraints you’re working with:Do the data labelers need to be subject matter experts, or could anyone anno-tate the data? The labels for a cat-versus-dog image classification problem canbe selected by anyone, but those for a dog breed classification task require spe-cialized knowledge. Meanwhile, annotating CT scans of bone fractures prettymuch requires a medical degree