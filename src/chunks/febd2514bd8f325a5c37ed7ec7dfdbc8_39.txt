the server in a decrypted form, since it will need to be seen bythe model (but note that you should use SSL encryption for the HTTP requestand answer).For instance, the image search engine project, the music recommender system, thecredit card fraud detection project, and the satellite imagery project are all good fitsfor serving via a REST API. A n  i m p o r t a n t  q u e s t i o n  w h e n  d e p l o y i n g  a  m o d e l  a s  a  R E S T  A P I  i s  w h e t h e r  y o uwant to host the code on your own, or whether you want to use a fully managed third-party cloud service. For instance, Cloud AI Platform, a Google product, lets you simplyupload your TensorFlow model to Google Cloud Storage (GCS), and it gives you anAPI endpoint to query it. It takes care of many practical details such as batching pre-dictions, load balancing, and scaling. DEPLOYING A MODEL ON A DEVICESometimes, you may need your model to live on the same device that runs the applica-tion that uses it—maybe a smartphone, an embedded ARM CPU on a robot, or amicrocontroller on a tiny device. You may have seen a camera capable of automati-cally detecting people and faces in the scenes you pointed it at: that was probably asmall deep learning model running directly on the camera. You should use this setup whenYour model has strict latency constraints or needs to run in a low-connectivityenvironment. If you’re building an immersive augmented reality application,querying a remote server is not a viable option