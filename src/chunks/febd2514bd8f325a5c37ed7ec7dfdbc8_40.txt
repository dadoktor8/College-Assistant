to run in a low-connectivityenvironment. If you’re building an immersive augmented reality application,querying a remote server is not a viable option.Your model can be made sufficiently small that it can run under the memory andpower constraints of the target device. You can use the TensorFlow Model Opti-mization Toolkit to help with this (www.tensorflow.org/model_optimization).Getting the highest possible accuracy isn’t mission critical for your task. Thereis always a trade-off between runtime efficiency and accuracy, so memory andpower constraints often require you to ship a model that isn’t quite as good asthe best model you could run on a large GPU.The input data is strictly sensitive and thus shouldn’t be decryptable on aremote server.
168CHAPTER 6The universal workflow of machine learningOur spam detection model will need to run on the end user’s smartphone as part ofthe chat app, because messages are end-to-end encrypted and thus cannot be read bya remotely hosted model. Likewise, the bad-cookie detection model has strict latencyconstraints and will need to run at the factory. Thankfully, in this case, we don’t haveany power or space constraints, so we can actually run the model on a GPU. To deploy a Keras model on a smartphone or embedded device, your go-to solutionis TensorFlow Lite (www.tensorflow.org/lite)