l with user-generated data. Concept drift occurs when the properties of the production datachange over time, causing model accuracy to gradually decay. A music recommenda-tion engine trained in the year 2013 may not be very effective today. Likewise, theIMDB dataset you worked with was collected in 2011, and a model trained on it would
159Define the tasklikely not perform as well on reviews from 2020 compared to reviews from 2012, asvocabulary, expressions, and movie genres evolve over time. Concept drift is particu-larly acute in adversarial contexts like credit card fraud detection, where fraud pat-terns change practically every day. Dealing with fast concept drift requires constantdata collection, annotation, and model retraining. Keep in mind that machine learning can only be used to memorize patterns thatare present in your training data. You can only recognize what you’ve seen before.Using machine learning trained on past data to predict the future is making theassumption that the future will behave like the past. That often isn’t the case.The problem of sampling biasA particularly insidious and common case of non-representative data is samplingbias. Sampling bias occurs when your data collection process interacts with whatyou are trying to predict, resulting in biased measurements. A famous historicalexample occurred in the 1948 US presidential election. On election night, the Chi-cago Tribune printed the headline “DEWEY DEFEATS TRUMAN