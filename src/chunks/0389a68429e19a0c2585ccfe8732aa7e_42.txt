s laptop or smartphone is likely to be slower than one running on a largeGPU on your own server, you don’t have the extra 100 ms of network round trip.You need your app to keep working without connectivity, after the model hasbeen downloaded and cached.You should only go with this option if your model is small enough that it won’t hog theCPU, GPU, or RAM of your user’s laptop or smartphone. In addition, since the entiremodel will be downloaded to the user’s device, you should make sure that nothingabout the model needs to stay confidential. Be mindful of the fact that, given a traineddeep learning model, it is usually possible to recover some information about the train-ing data: better not to make your trained model public if it was trained on sensitive data. To deploy a model in JavaScript, the TensorFlow ecosystem includes TensorFlow.js(www.tensorflow.org/js), a JavaScript library for deep learning that implementsalmost all of the Keras API (originally developed under the working name WebKeras)as well as many lower-level TensorFlow APIs. You can easily import a saved Kerasmodel into TensorFlow.js to query it as part of your browser-based JavaScript app oryour desktop Electron app. 
169Deploy the modelINFERENCE MODEL OPTIMIZATIONOptimizing your model for inference is especially important when deploying in anenvironment with strict constraints on available power and memory (smartphonesand embedded devices) or for applications with low latency requirements