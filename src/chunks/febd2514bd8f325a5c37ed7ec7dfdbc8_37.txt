would be missed. An average of 266 fraudulent transactions would becorrectly caught.” Clearly relate the model’s performance metrics to business goals. You should also make sure to discuss with stakeholders the choice of key launchparameters—for instance, the probability threshold at which a transaction should beflagged (different thresholds will produce different false negative and false positiverates). Such decisions involve trade-offs that can only be handled with a deep under-standing of the business context. 6.3.2 Ship an inference modelA machine learning project doesn’t end when you arrive at a Colab notebook that cansave a trained model. You rarely put in production the exact same Python modelobject that you manipulated during training. First, you may want to export your model to something other than Python:Your production environment may not support Python at all—for instance, ifit’s a mobile app or an embedded system.If the rest of the app isn’t in Python (it could be in JavaScript, C++, etc.), the useof Python to serve a model may induce significant overhead.Second, since your production model will only be used to output predictions (a phasecalled inference), rather than for training, you have room to perform various optimiza-tions that can make the model faster and reduce its memory footprint. Let’s take a quick look at the different model deployment options you have available