tatistical power and you’re able to overfit, you know you’re on theright path. At this point, your goal becomes to maximize generalization performance. This phase will take the most time: you’ll repeatedly modify your model, train it,evaluate on your validation data (not the test data at this point), modify it again, andrepeat, until the model is as good as it can get. Here are some things you should try:Try different architectures; add or remove layers.Add dropout.If your model is small, add L1 or L2 regularization.Try different hyperparameters (such as the number of units per layer or thelearning rate of the optimizer) to find the optimal configuration.Optionally, iterate on data curation or feature engineering: collect and anno-tate more data, develop better features, or remove features that don’t seem tobe informative.It’s possible to automate a large chunk of this work by using automated hyperparametertuning software, such as KerasTuner. We’ll cover this in chapter 13. Be mindful of the following: Every time you use feedback from your validation pro-cess to tune your model, you leak information about the validation process into themodel. Repeated just a few times, this is innocuous; done systematically over manyiterations, it will eventually cause your model to overfit to the validation process (eventhough no model is directly trained on any of the validation data). This makes theevaluation process less reliable